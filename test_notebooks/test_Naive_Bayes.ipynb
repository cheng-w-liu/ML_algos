{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processText(raw_texts):\n",
    "    STOP_WORDS = stopwords.words('english')\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')    \n",
    "    \n",
    "    raw_data = []\n",
    "    for raw in raw_texts:\n",
    "        words = [w.lower().strip() for w in tokenizer.tokenize(raw)]\n",
    "        words = [w for w in words if w not in STOP_WORDS and w != '']\n",
    "        raw_data.append(words)    \n",
    "    return raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def splitData(raw_features, raw_targets, test_fraction=0.2):\n",
    "    train_done = False\n",
    "    test_done = False\n",
    "    n_iter = 0\n",
    "    n_classes = np.unique(raw_targets)\n",
    "    while not train_done or not test_done:\n",
    "        X_train_raw, X_test_raw, y_train, y_test = train_test_split(raw_features, raw_targets, test_size=test_fraction)\n",
    "        \n",
    "        train_done = len(np.unique(y_train) == len(n_classes))\n",
    "        test_done = len(np.unique(y_test) == len(n_classes))\n",
    "        \n",
    "        if train_done and test_done:\n",
    "            return X_train_raw, X_test_raw, y_train, y_test\n",
    "        else:\n",
    "            n_iter += 1\n",
    "            \n",
    "        if n_iter == 20:\n",
    "            if train_done:\n",
    "                print('test set has missing classes')\n",
    "                return X_train_raw, X_test_raw, y_train, y_test\n",
    "            else:\n",
    "                print('both train and test sets have missing classes. use entier data instead')\n",
    "                return raw_features, raw_features, raw_target, raw_target\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fitFeatures(X_train_raw):\n",
    "    features = []\n",
    "    for train_example in X_train_raw:\n",
    "        if len(train_example) == 0:\n",
    "            continue\n",
    "        values = [e for e in train_example]\n",
    "        features = list(set(features).union(set(values)))\n",
    "    features = [feat for feat in features if feat is not None and feat is not np.nan and feat != '']\n",
    "    features.sort()\n",
    "    p = len(features)\n",
    "    feature2idx = {}\n",
    "    idx2feature = {}\n",
    "    for i, feat in enumerate(features):\n",
    "        feature2idx[feat] = i\n",
    "        idx2feature[i] = feat\n",
    "    return feature2idx, idx2feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rawTokens2Vector(raw_example, features2idx):\n",
    "    p = len(feature2idx)\n",
    "    vec = np.zeros(p)\n",
    "    if len(raw_example) == 0:\n",
    "        return vec\n",
    "    for word in raw_example:\n",
    "        if word in features2idx:\n",
    "            vec[features2idx[word]] = 1.0\n",
    "    return vec    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encodeFeatures(X_train_raw, X_test_raw, feature2idx):\n",
    "    X_train = []\n",
    "    for raw_example in X_train_raw:\n",
    "        vec = rawTokens2Vector(raw_example, feature2idx)\n",
    "        X_train.append(vec)\n",
    "    X_train = np.array(X_train)\n",
    "\n",
    "    X_test = []\n",
    "    for raw_example in X_test_raw:\n",
    "        vec = rawTokens2Vector(raw_example, feature2idx)\n",
    "        X_test.append(vec)\n",
    "    X_test = np.array(X_test)\n",
    "    \n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_features = processText(twenty_train.data)    \n",
    "raw_targets = twenty_train.target\n",
    "# twenty_train.target_names\n",
    "X_train_raw, X_test_raw, y_train, y_test = splitData(raw_features, raw_targets)\n",
    "feature2idx, idx2feature = fitFeatures(X_train_raw)\n",
    "X_train, X_test = encodeFeatures(X_train_raw, X_test_raw, feature2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test scikit-learn Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model = MultinomialNB()\n",
    "sk_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.965, testing accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = np.mean(sk_model.predict(X_train) == y_train)\n",
    "accuracy_test = np.mean(sk_model.predict(X_test) == y_test)\n",
    "print('training accuracy: {0:.3f}, testing accuracy: {1:.3f}'.format(accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.74000968e-30,   1.12329426e-22,   5.11748499e-29],\n",
       "       [  6.20388949e-16,   3.91096442e-10,   8.11245011e-17],\n",
       "       [  6.42836867e-56,   2.45377937e-58,   8.96586584e-71],\n",
       "       [  1.59216891e-41,   8.40260471e-18,   1.56529743e-22],\n",
       "       [  1.80079182e-21,   2.78290537e-05,   1.08841080e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_model.predict_proba(X_train)[0:5, 0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test personal package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import naive_bayes\n",
    "reload(naive_bayes)\n",
    "from naive_bayes import MultinomialNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model = MultinomialNaiveBayes()\n",
    "my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.965, testing accuracy: 0.866\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = np.mean(my_model.predict(X_train) == y_train)\n",
    "accuracy_test = np.mean(my_model.predict(X_test) == y_test)\n",
    "print('training accuracy: {0:.3f}, testing accuracy: {1:.3f}'.format(accuracy_train, accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.74000968e-30,   1.12329426e-22,   5.11748499e-29],\n",
       "       [  6.20388949e-16,   3.91096442e-10,   8.11245011e-17],\n",
       "       [  6.42836867e-56,   2.45377937e-58,   8.96586584e-71],\n",
       "       [  1.59216891e-41,   8.40260471e-18,   1.56529743e-22],\n",
       "       [  1.80079182e-21,   2.78290537e-05,   1.08841080e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.predict_proba(X_train)[0:5, 0:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
